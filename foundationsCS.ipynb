{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8IdaiasV8z1",
    "outputId": "dc704db8-1435-4ad3-83c3-e3d676ced0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\feder\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\feder\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\feder\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\feder\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\feder\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\feder\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\feder\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\feder\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\feder\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\feder\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\feder\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\AppData\\Local\\Temp\\ipykernel_18964\\874685701.py:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  NST_EST2021_POP['Population'] = pd.to_numeric(NST_EST2021_POP['Population'].str.replace('.', ''))\n"
     ]
    }
   ],
   "source": [
    "# Loading data from CSV files and cleaning data\n",
    "dogs = pd.read_csv(\"dogs.csv\")\n",
    "travels = pd.read_csv(\"dogTravel.csv\", index_col=0)\n",
    "NST_EST2021_POP = pd.read_csv(\"NST-EST2021-POP.csv\", header=None, names=['State', 'Population'])\n",
    "NST_EST2021_POP['Population'] = pd.to_numeric(NST_EST2021_POP['Population'].str.replace('.', ''))\n",
    "\n",
    "# Shift the values of the specified columns to the next column and convert the \"accessed\" and \"posted\" columns to dates\n",
    "cols_to_shift = [\"status\", \"posted\", \"contact_city\", \"contact_state\", \"contact_zip\", \"contact_country\", \"stateQ\",\"accessed\"]\n",
    "dogs.loc[dogs[\"status\"] != \"adoptable\", cols_to_shift] = dogs.loc[dogs[\"status\"] != \"adoptable\", cols_to_shift].shift(1, axis=1)\n",
    "dogs['accessed'] = pd.to_datetime(dogs['accessed'], format='%Y-%m-%d').dt.date\n",
    "dogs['posted'] = pd.to_datetime(dogs['posted'], format='%Y-%m-%dT%H:%M:%S%z').dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Extract all dogs with status that is not adoptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Dogs that are not adoptable\n",
      "644      41330726\n",
      "5549     38169117\n",
      "10888    45833989\n",
      "11983    45515547\n",
      "12495    45294115\n",
      "12600    45229004\n",
      "12613    45227052\n",
      "17619    45569380\n",
      "18611    44694387\n",
      "19747    36978896\n",
      "19845    33218331\n",
      "22161    42092005\n",
      "22229    39594038\n",
      "29283    45895274\n",
      "30471    45964719\n",
      "31581    44538917\n",
      "31888    41430442\n",
      "33000    45907639\n",
      "33527    45362806\n",
      "34188    32590894\n",
      "35065    31426754\n",
      "44830    46037827\n",
      "53168    44044071\n",
      "53539    27521132\n",
      "55434    38473806\n",
      "55467    34101432\n",
      "55915    45958435\n",
      "55975    45927580\n",
      "56013    45916348\n",
      "56248    45733027\n",
      "56464    45413997\n",
      "56473    45406516\n",
      "56541    45264615\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "not_adoptable = dogs[dogs['status'] != 'adoptable']\n",
    "print(\"Task 1: Dogs that are not adoptable\")\n",
    "print(not_adoptable['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2. For each (primary) breed, determine the number of dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: Number of dogs per primary breed\n",
      "Pit Bull Terrier                7890\n",
      "Labrador Retriever              7198\n",
      "Chihuahua                       3766\n",
      "Mixed Breed                     3242\n",
      "Terrier                         2641\n",
      "                                ... \n",
      "Wirehaired Pointing Griffon        1\n",
      "Boykin Spaniel                     1\n",
      "Old English Sheepdog               1\n",
      "Belgian Shepherd / Laekenois       1\n",
      "Tosa Inu                           1\n",
      "Name: breed_primary, Length: 216, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "breed_counts = dogs['breed_primary'].value_counts()\n",
    "print(\"Task 2: Number of dogs per primary breed\")\n",
    "print(breed_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3. For each (primary) breed, determine the ratio between the number of dogs of Mixed Breed and those not of Mixed Breed. Hint: look at the secondary_breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3: Ratio of Mixed Breed to Non-Mixed Breed for each primary breed\n",
      "breed_mixed                        Non-Mixed Breed  Mixed Breed  \\\n",
      "breed_primary                                                     \n",
      "Affenpinscher                                   12            5   \n",
      "Afghan Hound                                     0            4   \n",
      "Airedale Terrier                                 2           17   \n",
      "Akbash                                           1            2   \n",
      "Akita                                           98           83   \n",
      "...                                            ...          ...   \n",
      "Wirehaired Pointing Griffon                      0            1   \n",
      "Wirehaired Terrier                              15           45   \n",
      "Xoloitzcuintli / Mexican Hairless                6            5   \n",
      "Yellow Labrador Retriever                       36          122   \n",
      "Yorkshire Terrier                              157          203   \n",
      "\n",
      "breed_mixed                        Mixed/Non-Mixed Ratio  \n",
      "breed_primary                                             \n",
      "Affenpinscher                                   0.416667  \n",
      "Afghan Hound                                         inf  \n",
      "Airedale Terrier                                8.500000  \n",
      "Akbash                                          2.000000  \n",
      "Akita                                           0.846939  \n",
      "...                                                  ...  \n",
      "Wirehaired Pointing Griffon                          inf  \n",
      "Wirehaired Terrier                              3.000000  \n",
      "Xoloitzcuintli / Mexican Hairless               0.833333  \n",
      "Yellow Labrador Retriever                       3.388889  \n",
      "Yorkshire Terrier                               1.292994  \n",
      "\n",
      "[216 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "breed_mixed_counts = dogs.groupby('breed_primary')['breed_mixed'].value_counts().unstack(fill_value=0)\n",
    "breed_mixed_counts['Mixed/Non-Mixed Ratio'] = breed_mixed_counts[True] / breed_mixed_counts[False]\n",
    "breed_mixed_counts = breed_mixed_counts.rename(columns={True: 'Mixed Breed', False: 'Non-Mixed Breed'})\n",
    "print(\"Task 3: Ratio of Mixed Breed to Non-Mixed Breed for each primary breed\")\n",
    "print(breed_mixed_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 4. For each (primary) breed, determine the earliest and the latest posted timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4: Posted timestamp range per primary breed\n",
      "                                          min         max\n",
      "breed_primary                                            \n",
      "Affenpinscher                      2012-03-08  2019-09-14\n",
      "Afghan Hound                       2017-06-29  2019-07-27\n",
      "Airedale Terrier                   2014-06-13  2019-09-19\n",
      "Akbash                             2019-07-21  2019-08-23\n",
      "Akita                              2012-03-03  2019-09-20\n",
      "...                                       ...         ...\n",
      "Wirehaired Pointing Griffon        2016-06-29  2016-06-29\n",
      "Wirehaired Terrier                 2012-11-27  2019-09-19\n",
      "Xoloitzcuintli / Mexican Hairless  2007-02-01  2019-09-08\n",
      "Yellow Labrador Retriever          2010-05-31  2019-09-20\n",
      "Yorkshire Terrier                  2012-02-04  2019-09-20\n",
      "\n",
      "[216 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "breed_posted_range = dogs.groupby('breed_primary')['posted'].agg(['min', 'max'])\n",
    "print(\"Task 4: Posted timestamp range per primary breed\")\n",
    "print(breed_posted_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 5. For each state, compute the sex imbalance, that is the difference between male and female dogs. In which state this imbalance is largest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5: Sex imbalance for each state\n",
      "sex            Female  Male  Unknown  Male/Female Ratio  Male-Female Delta\n",
      "contact_state                                                             \n",
      "AK                  7     8        0           1.142857                  1\n",
      "AL                716   712        0           0.994413                  4\n",
      "AR                351   344        0           0.980057                  7\n",
      "AZ               1067  1181        1           1.106842                114\n",
      "CA                777   887        0           1.141570                110\n",
      "CO                912   861        0           0.944079                 51\n",
      "CT                682   740        0           1.085044                 58\n",
      "DC                176   160        0           0.909091                 16\n",
      "DE                148   148        0           1.000000                  0\n",
      "FL               1279  1380        0           1.078968                101\n",
      "GA               1727  1752        0           1.014476                 25\n",
      "HI                 28    41        0           1.464286                 13\n",
      "IA                202   283        0           1.400990                 81\n",
      "ID                 24    25        0           1.041667                  1\n",
      "IL                507   608        0           1.199211                101\n",
      "IN                851  1029        0           1.209166                178\n",
      "KS                235   235        0           1.000000                  0\n",
      "KY                507   616        0           1.214990                109\n",
      "LA                444   467        2           1.051802                 23\n",
      "MA                459   487        0           1.061002                 28\n",
      "MD                679   815        0           1.200295                136\n",
      "ME                287   258        0           0.898955                 29\n",
      "MI                317   356        0           1.123028                 39\n",
      "MN                462   496        0           1.073593                 34\n",
      "MO                425   495        0           1.164706                 70\n",
      "MS                275   235        0           0.854545                 40\n",
      "MT                  7    11        0           1.571429                  4\n",
      "NB                  1     1        0           1.000000                  0\n",
      "NC               1282  1345        0           1.049142                 63\n",
      "ND                 28    36        0           1.285714                  8\n",
      "NE                 61    59        0           0.967213                  2\n",
      "NH                172   163        0           0.947674                  9\n",
      "NJ               1483  1539        0           1.037761                 56\n",
      "NM                310   327        0           1.054839                 17\n",
      "NV                402   456        0           1.134328                 54\n",
      "NY               1945  2062        0           1.060154                117\n",
      "OH               1234  1439        0           1.166126                205\n",
      "OK                814   822        0           1.009828                  8\n",
      "OR                 33    58        0           1.757576                 25\n",
      "PA               1371  1454        0           1.060540                 83\n",
      "QC                  7     7        0           1.000000                  0\n",
      "RI                306   301        0           0.983660                  5\n",
      "SC                759   859        0           1.131752                100\n",
      "SD                  7    17        0           2.428571                 10\n",
      "TN                826   945        0           1.144068                119\n",
      "TX                287   279        0           0.972125                  8\n",
      "UT                203   282        0           1.389163                 79\n",
      "VA               1451  1610        0           1.109580                159\n",
      "VT                234   276        0           1.179487                 42\n",
      "WA                598   686        0           1.147157                 88\n",
      "WI                265   277        0           1.045283                 12\n",
      "WV                232   333        0           1.435345                101\n",
      "WY                 21    31        0           1.476190                 10\n",
      "The state with the largest Male-Female Delta is OH\n",
      "The state with the largest Male/Female Ratio is SD\n"
     ]
    }
   ],
   "source": [
    "state_sex_counts = dogs.groupby(['contact_state', 'sex'])['id'].count().unstack(fill_value=0)\n",
    "state_sex_counts['Male/Female Ratio'] = state_sex_counts['Male'] / state_sex_counts['Female']\n",
    "state_sex_counts['Male-Female Delta'] = (state_sex_counts['Male'] - state_sex_counts['Female']).abs()\n",
    "max_delta_state = state_sex_counts['Male-Female Delta'].idxmax()\n",
    "max_ratio_state = state_sex_counts['Male/Female Ratio'].idxmax()\n",
    "print(\"Task 5: Sex imbalance for each state\")\n",
    "print(state_sex_counts)\n",
    "print(f\"The state with the largest Male-Female Delta is {max_delta_state}\")\n",
    "print(f\"The state with the largest Male/Female Ratio is {max_ratio_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 6. For each pair (age, size), determine the average duration of the stay and the average cost of stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6: Stay statistics per age and size\n",
      "                    stay_duration   stay_cost\n",
      "age    size                                  \n",
      "Adult  Extra Large      89.015414  232.591561\n",
      "       Large            89.531943  238.661141\n",
      "       Medium           89.421036  238.258977\n",
      "       Small            89.407479  238.974838\n",
      "Baby   Extra Large      87.032967  237.180879\n",
      "       Large            89.701564  238.698827\n",
      "       Medium           89.577668  237.108131\n",
      "       Small            89.958291  239.083810\n",
      "Senior Extra Large      88.861111  235.232361\n",
      "       Large            88.984298  237.507364\n",
      "       Medium           89.810052  238.514615\n",
      "       Small            89.073626  238.282286\n",
      "Young  Extra Large      90.586345  245.835582\n",
      "       Large            90.104206  238.149506\n",
      "       Medium           89.515123  239.304603\n",
      "       Small            89.814275  241.540069\n"
     ]
    }
   ],
   "source": [
    "age_size_stay_stats = dogs.groupby(['age', 'size'])[['stay_duration', 'stay_cost']].mean()\n",
    "print(\"Task 6: Stay statistics per age and size\")\n",
    "print(age_size_stay_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 7. Find the dogs involved in at least 3 travels. Also list the breed of those dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 7: Dogs involved in at least 3 travels\n",
      "             id        breed_primary\n",
      "1159   45642530                Jindo\n",
      "6835   46039420        Border Collie\n",
      "8526   40036107     Pit Bull Terrier\n",
      "10681  45851842   Labrador Retriever\n",
      "10803  45841145          Mixed Breed\n",
      "...         ...                  ...\n",
      "56850  41144335            Chihuahua\n",
      "56864  40103682          Rat Terrier\n",
      "56875  38664932     Pit Bull Terrier\n",
      "56879  38495992     Pit Bull Terrier\n",
      "57263  45588395  German Shepherd Dog\n",
      "\n",
      "[563 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dogs_travel_counts = travels.groupby('id')['contact_city'].count()\n",
    "dogs_with_3_travels = dogs_travel_counts[dogs_travel_counts >= 3].index\n",
    "dogs_with_3_travels_breeds = dogs[dogs['id'].isin(dogs_with_3_travels)][['id', 'breed_primary']]\n",
    "print(\"Task 7: Dogs involved in at least 3 travels\")\n",
    "print(dogs_with_3_travels_breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 8. Fix the travels table so that the correct state is computed from the manual and the found fields. If manual is not missing, then it overrides what is stored in found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 8: Correct state computed from manual and found fields\n",
      "             id    contact_city contact_state\n",
      "index                                        \n",
      "0      44520267           Anoka            MN\n",
      "1      44698509          Abacos            BS\n",
      "2      45983838            Adam            MD\n",
      "3      44475904     Saint Cloud            MN\n",
      "4      43877389          Pueblo            CO\n",
      "...         ...             ...           ...\n",
      "6189   40492179        Fairmont            WV\n",
      "6190   45799729  Eagle Mountain            UT\n",
      "6191   34276515          Newnan            GA\n",
      "6192   44519341           Young            OH\n",
      "6193   36659999        New York            NY\n",
      "\n",
      "[6194 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "state_codes = {\n",
    "    'Afghanistan': 'AF', 'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'Azerbaijan': 'AZ', 'Bahamas': 'BS', 'Bahrain': 'BH', 'California': 'CA', 'China': 'CN',\n",
    "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Egypt': 'EG', 'England': 'EN',\n",
    "    'Florida': 'FL', 'Georgia': 'GA', 'Greece': 'GR', 'Hawaii': 'HI', 'Honduras': 'HO',\n",
    "    'Idaho': 'ID', 'Illinois': 'IL', 'India': 'IND', 'Indiana': 'IN', 'Iowa': 'IA', 'Iran': 'IR',\n",
    "    'Ireland': 'IR', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME',\n",
    "    'Maryland': 'MD', 'Massachusetts': 'MA', 'Mexico': 'MX', 'Michigan': 'MI', 'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oman': 'OM',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Qatar': 'QA',\n",
    "    'Rhode Island': 'RI', 'Russia': 'RU', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
    "    'South Korea': 'KR', 'Spain': 'ES', 'St. Croix': 'SC', 'St. Maarten': 'SM', 'St. Simon': 'SI',\n",
    "    'St. Thomas': 'ST', 'Taiwan': 'TW', 'Tennessee': 'TN', 'Texas': 'TX', 'Thailand': 'TH',\n",
    "    'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'Washington DC': 'DC',\n",
    "    'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "\n",
    "travels['manual'] = travels['manual'].map(state_codes)\n",
    "travels.loc[travels['manual'].notnull(), 'contact_state'] = travels['manual']\n",
    "travels.loc[travels['manual'].notnull(), 'contact_city'] = travels['found']\n",
    "print(\"Task 8: Correct state computed from manual and found fields\")\n",
    "print(travels[['id', 'contact_city', 'contact_state']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 9. For each state, compute the ratio between the number of travels and the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 9: Ratio between the number of travels and the population for each state\n",
      "   State Code  Travel/Population Ratio\n",
      "0          AL             1.612172e-05\n",
      "1          AR             1.162202e-05\n",
      "2          AZ             9.508492e-06\n",
      "3          CA             4.223761e-06\n",
      "4          CO             1.125792e-05\n",
      "5          CT             2.024435e-05\n",
      "6          DE             5.252801e-05\n",
      "7          FL             7.567954e-06\n",
      "8          GA             1.288286e-05\n",
      "9          HI             1.374314e-06\n",
      "10         IA             6.268867e-06\n",
      "11         ID             5.437424e-07\n",
      "12         IL             3.043901e-06\n",
      "13         IN             8.842348e-06\n",
      "14         KS             1.021144e-06\n",
      "15         KY             1.176252e-05\n",
      "16         LA             7.514346e-06\n",
      "17         MA             1.152218e-05\n",
      "18         MD             5.941180e-05\n",
      "19         ME             1.181774e-04\n",
      "20         MI             5.854725e-06\n",
      "21         MN             2.488393e-05\n",
      "22         MO             7.473704e-06\n",
      "23         MS             8.779990e-06\n",
      "24         NC             2.461830e-05\n",
      "25         ND             1.283542e-06\n",
      "26         NH             2.032625e-05\n",
      "27         NJ             4.586073e-05\n",
      "28         NM             4.628051e-05\n",
      "29         NV             5.153620e-06\n",
      "30         NY             2.074129e-05\n",
      "31         OH             1.372946e-05\n",
      "32         OK             8.587262e-06\n",
      "33         OR             4.248032e-06\n",
      "34         PA             2.207234e-05\n",
      "35         RI             5.923204e-05\n",
      "36         SC             2.520307e-05\n",
      "37         TN             1.996863e-05\n",
      "38         TX             1.221458e-05\n",
      "39         UT             1.803390e-05\n",
      "40         VA             1.006790e-04\n",
      "41         VT             4.198564e-05\n",
      "42         WA             3.828543e-05\n",
      "43         WI             1.323443e-05\n",
      "44         WV             3.679512e-05\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to the NST_EST2021_POP dataframe with the abbreviated state codes\n",
    "NST_EST2021_POP['State Code'] = NST_EST2021_POP['State'].map(state_codes)\n",
    "\n",
    "# Calculating the number of travels per state using the travels dataframe and the contact_state column as the grouping key.\n",
    "travels_per_state = travels.groupby('contact_state').size().reset_index(name='Travels')\n",
    "\n",
    "# Merging the travels_per_state and NST_EST2021_POP dataframes using the abbreviated state codes as the merge key.\n",
    "travels_population = pd.merge(travels_per_state, NST_EST2021_POP, left_on='contact_state', right_on='State Code')\n",
    "\n",
    "# Calculating the ratio between the number of travels and the population for each state.\n",
    "travels_population['Travel/Population Ratio'] = travels_population['Travels'] / travels_population['Population']\n",
    "\n",
    "# Printing the final result.\n",
    "print(\"Task 9: Ratio between the number of travels and the population for each state\")\n",
    "print(travels_population[['State Code', 'Travel/Population Ratio']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 10. For each dog, compute the number of days from the posted day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 10: Number of days from the posted day to the day of last access for each dog\n",
      "             id  Days from Post to Access\n",
      "0      46042150                         0\n",
      "1      46042002                         0\n",
      "2      46040898                         0\n",
      "3      46039877                         0\n",
      "4      46039306                         0\n",
      "...         ...                       ...\n",
      "58175  44605893                       140\n",
      "58176  44457061                       160\n",
      "58177  42865848                       358\n",
      "58178  42734734                       373\n",
      "58179  42663515                       382\n",
      "\n",
      "[58180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "days_from_post_to_access = (dogs['accessed'] - dogs['posted']).dt.days\n",
    "dogs['Days from Post to Access'] = days_from_post_to_access\n",
    "print(\"Task 10: Number of days from the posted day to the day of last access for each dog\")\n",
    "print(dogs[['id', 'Days from Post to Access']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 11. Partition the dogs according to the number of weeks from the posted day to the day of last access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 11: Dogs partitioned by the number of weeks from the posted day to the day of last access\n",
      "Weeks from Post to Access\n",
      "0      [46042150, 46042002, 46040898, 46039877, 46039...\n",
      "1      [45967088, 45966541, 45966538, 45966526, 45966...\n",
      "2      [45892818, 45892807, 45892791, 45892773, 45892...\n",
      "3      [45797757, 45797240, 45797231, 45791070, 45790...\n",
      "4      [45727282, 45715803, 45710620, 45709771, 45705...\n",
      "                             ...                        \n",
      "729                                            [5142790]\n",
      "746                                            [4527948]\n",
      "811                                            [2613506]\n",
      "812                                            [2592031]\n",
      "852                                             [604115]\n",
      "Name: id, Length: 579, dtype: object\n"
     ]
    }
   ],
   "source": [
    "weeks_from_post_to_access = (dogs['accessed'] - dogs['posted']).dt.days // 7\n",
    "dogs['Weeks from Post to Access'] = weeks_from_post_to_access\n",
    "dogs_partitioned = dogs.groupby('Weeks from Post to Access')['id'].apply(list)\n",
    "print(\"Task 11: Dogs partitioned by the number of weeks from the posted day to the day of last access\")\n",
    "print(dogs_partitioned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 12. Find for duplicates in the dogs dataset. Two records are duplicates if they have (1) same breeds and sex, and (2) they share at least 90% of the words in the description field. Extra points if you find and implement a more refined for determining if two rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3        46039877\n",
      "14       46038070\n",
      "15       46038064\n",
      "16       46038065\n",
      "17       46038067\n",
      "           ...   \n",
      "58174    44629272\n",
      "58175    44605893\n",
      "58176    44457061\n",
      "58178    42734734\n",
      "58179    42663515\n",
      "Name: id, Length: 11422, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def common_word_percentage(row):\n",
    "    # Tokenize the description\n",
    "    description = row['description']\n",
    "    if pd.isnull(description):\n",
    "        return 0\n",
    "    word_tokens = word_tokenize(description)\n",
    "\n",
    "    # Calculate the percentage of common words\n",
    "    common_words = set(word_tokens).intersection(row['group_description'])\n",
    "    return 2 * len(common_words) / (len(word_tokens) + len(row['group_description']))\n",
    "\n",
    "# Find the rows with exactly the same description using the duplicated() method\n",
    "duplicates_100 = dogs[dogs.duplicated(subset=['sex', 'breed_primary', 'description'], keep=False)]\n",
    "\n",
    "# Find the rows with less than 100% common words\n",
    "remaining_rows = dogs.drop(duplicates_100.index)\n",
    "\n",
    "# Group by 'sex' and 'breed_primary' and create a new column with the concatenated descriptions of each group\n",
    "grouped = remaining_rows.groupby(['sex', 'breed_primary'])\n",
    "remaining_rows['group_description'] = grouped['description'].transform(lambda x: ' '.join(x.dropna()))\n",
    "\n",
    "# Create a new column with the percentage of common words\n",
    "remaining_rows['common_word_percentage'] = remaining_rows.apply(common_word_percentage, axis=1)\n",
    "\n",
    "# Filter the groups based on the condition that the common word percentage is greater than or equal to 0.9\n",
    "duplicates_90 = grouped.filter(lambda x: x['common_word_percentage'].max() >= 0.9)\n",
    "\n",
    "# Concatenate the two dataframes with 100% and 90% common words\n",
    "duplicates = pd.concat([duplicates_100, duplicates_90])\n",
    "\n",
    "# Drop the columns that were added for the calculation\n",
    "duplicates = duplicates.drop(columns=['group_description', 'common_word_percentage'])\n",
    "# Print the dataframe of duplicate records\n",
    "print(duplicates['id'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
